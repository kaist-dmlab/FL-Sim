{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test hfl_core.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import hfl_core\n",
    "\n",
    "w_ofNid1 = [ np.array([[4, 0], [4, 0]], dtype=np.float32), np.array([8, 0, 8], dtype=np.float32) ]\n",
    "w_ofNid2 = [ np.array([[0, 4], [0, 4]], dtype=np.float32), np.array([0, 8, 0], dtype=np.float32) ]\n",
    "w_byNid = [ w_ofNid1, w_ofNid2 ]\n",
    "weight_byNid = [ 1, 3 ]\n",
    "w_avg = hfl_core.federated_aggregate1(w_byNid, weight_byNid)\n",
    "\n",
    "assert( w_avg[0].tolist() == [[1, 3], [1, 3]] )\n",
    "assert( w_avg[1].tolist() == [2, 6, 2] )\n",
    "assert( type(w_avg[0][0,0]) == np.float32 )\n",
    "assert( np.linalg.norm(hfl_core.np_flatten(w_ofNid1) - hfl_core.np_flatten(w_ofNid2)) == 16 )\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test hfl_alg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'hfl_alg' has no attribute 'calc_Q'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bb3d718a6987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhfl_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mhfl_alg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'hfl_alg' has no attribute 'calc_Q'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import hfl_core\n",
    "import hfl_alg\n",
    "import hfl_struct\n",
    "import hfl_util\n",
    "\n",
    "assert( hfl_alg.calc_Q(2, 2, 0.5, 2, 0.5, 2, 0.5, 2) == 8 )\n",
    "\n",
    "trainData, testData = tf.keras.datasets.mnist.load_data()\n",
    "(trainData_byNid, train_z) = hfl_util.groupByEdge('cnn', 'mnist-o', trainData, 'one', 'one', 100, 10, True)\n",
    "\n",
    "g_is__w = w_byNid\n",
    "weight_byNid = [ 1, 3 ]\n",
    "g__w = hfl_core.federated_aggregate1(g_is__w, weight_byNid)\n",
    "\n",
    "numNodes = 2\n",
    "numGroups = 2\n",
    "z = [0, 1]\n",
    "testData_byNid = np.array([ trainData_byNid[i] for i in range(numNodes) ])\n",
    "c = hfl_struct.Cloud(None, np.array([ trainData_byNid[i] for i in range(numNodes) ]), numGroups)\n",
    "c.digest(z, debugging=True)\n",
    "\n",
    "# 1. deltaMap 을 이용한 delta 구하기\n",
    "(deltaMap, DeltaMap) = hfl_alg.calc_deltaMap(c, g_is__w, g__w, numNodes)\n",
    "assert( deltaMap == [[0.0, 16.0], [16.0, 0.0]] )\n",
    "assert( DeltaMap == [[12.0, 4.0], [12.0, 4.0]] )\n",
    "\n",
    "(delta1, Delta1) = hfl_alg.calc_delta(c, deltaMap, DeltaMap)\n",
    "\n",
    "# 2. deltaMap 없이 delta 구하기\n",
    "def federated_delta(g_global, g_local_byId, weight_byId):\n",
    "    return np.average([ hfl_core.np_normOfDiff(g_global, g_local) for g_local in g_local_byId ], weights=weight_byId)\n",
    "g_ks__w = [] ; idxBegin = 0 ; idxEnd = 0\n",
    "for g in c.groups:\n",
    "    idxEnd += len(g.get_N_k())\n",
    "    g_k_is__w = g_is__w[idxBegin:idxEnd]\n",
    "    g_k__w = hfl_core.federated_aggregate1(g_k_is__w, g.get_D_k_is())\n",
    "    g_ks__w.append(g_k__w)\n",
    "    idxBegin = idxEnd\n",
    "    \n",
    "delta_ks2 = [] ; idxBegin = 0 ; idxEnd = 0\n",
    "for k, g in enumerate(c.groups):\n",
    "    idxEnd += len(g.get_N_k())\n",
    "    g_k_is__w = g_is__w[idxBegin:idxEnd]\n",
    "    g_k__w = g_ks__w[k]\n",
    "    delta_k2 = federated_delta(g_k__w, g_k_is__w, g.get_D_k_is())\n",
    "    delta_ks2.append(delta_k2)\n",
    "    idxBegin = idxEnd\n",
    "delta2 = np.average(delta_ks2, weights=c.get_D_ks())\n",
    "Delta2 = federated_delta(g__w, g_ks__w, c.get_D_ks())\n",
    "assert( delta1 == delta2 )\n",
    "assert( Delta1 == Delta2 )\n",
    "print('Completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
